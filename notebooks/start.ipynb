{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile .env \n",
    "OPENAI_ENDPOINT=https://<YOUR-ENDPOINT>.openai.azure.com/\n",
    "OPENAI_API_KEY=<YOUR-API-KEY>\n",
    "OPENAI_COMPLETION_MODEL=<YOUR-COMPLETION-MODEL-NAME>\n",
    "OPENAI_EMBEDDING_MODEL=<YOUR-EMBEDDING-MODEL-NAME>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dotenv\n",
    "dotenv.load_dotenv()\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import re\n",
    "import time\n",
    "import os "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data read\n",
    "def read_df(path):\n",
    "    df = pd.read_csv(path)\n",
    "    cols_kept = [\n",
    "        'name', \n",
    "        'reviews.doRecommend','reviews.numHelpful','reviews.rating','reviews.text',\n",
    "        'reviews.title',\n",
    "    ]\n",
    "    df = df[cols_kept]\n",
    "    df['ml_id'] = df.index\n",
    "    return df \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data cleanup\n",
    "def normalize_text(s: str, sep_token = \" \\n \"):\n",
    "    s = s.replace(\"\\n\", \" \")\n",
    "    s = re.sub(r\",\",\"\",s)\n",
    "    s = re.sub(r'\\.+', '.', s)\n",
    "    s = re.sub(r'(\\. )+', '. ', s)\n",
    "    s = re.sub(r'\\s+', ' ', s)\n",
    "    s = s.strip()\n",
    "\n",
    "    return s\n",
    "\n",
    "def clean_up_text(review_title:pd.Series, review_text:pd.Series)->pd.Series:\n",
    "    data = review_title+' ' + review_text\n",
    "    cleaned_text = data.apply(normalize_text)\n",
    "    return cleaned_text\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2TokenizerFast\n",
    "tokenizer = GPT2TokenizerFast.from_pretrained(\"gpt2\") \n",
    "\n",
    "def count_tokens(series:pd.Series, *,tokenizer=tokenizer) -> pd.Series:\n",
    "    n_tokens = series.apply(lambda x: len(tokenizer.encode(x)))\n",
    "    return n_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "openai.api_type = 'azure'\n",
    "openai.api_base = os.getenv('OPENAI_ENDPOINT')\n",
    "openai.api_key = os.getenv('OPENAI_API_KEY')\n",
    "openai.api_version = os.getenv('OPENAI_API_VERSION')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from typing import Tuple\n",
    "\n",
    "embedding_model = os.getenv('OPENAI_EMBEDDING_MODEL')\n",
    "\n",
    "embedding_cache={}\n",
    "def get_one_embedding(input: str)->list:\n",
    "    if input in embedding_cache:\n",
    "        return embedding_cache[input]\n",
    "    fail_counter = 1\n",
    "    while True:\n",
    "        try:\n",
    "            if fail_counter>3:\n",
    "                return None\n",
    "            if fail_counter>1:\n",
    "                print(f'try: {fail_counter}')\n",
    "            response = openai.Embedding.create(input=[input], engine=embedding_model)\n",
    "            ans= np.array(response.data[0].embedding)\n",
    "            embedding_cache[input] = ans\n",
    "            return ans\n",
    "\n",
    "        except openai.error.RateLimitError:\n",
    "            wait = 10\n",
    "            print(f'Rate limit... waiting for {wait} seconds ({input[:20]})')\n",
    "            time.sleep(wait)\n",
    "            fail_counter +=1\n",
    "\n",
    "\n",
    "def get_embedding(data: pd.Series)->Tuple[pd.Series, np.ndarray]:\n",
    "    series =  data.apply(lambda x: get_one_embedding(x))\n",
    "    matrix = np.stack(series.to_numpy())\n",
    "    return series, matrix\n",
    "\n",
    "def perform_pca(embedding_matrix:np.array, n_components:int=5)->np.ndarray:\n",
    "    reduced_matrix = PCA(n_components=n_components,random_state=0).fit_transform(embedding_matrix)\n",
    "    return reduced_matrix\n",
    "\n",
    "def perform_clustering(matrix:np.array, n_clusters:int=3)->pd.Series:\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=0, n_init=10).fit(matrix)\n",
    "    return pd.Series(kmeans.labels_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Persona:\n",
    "    def __init__(self, cluster_id:int, data:list[str]):\n",
    "        self.cluster_id=cluster_id\n",
    "        self.name = f'Persona {cluster_id}'\n",
    "        self.unprocessed_data = data \n",
    "        self.total_reviews = len(data)\n",
    "        self.processed_data = []\n",
    "        self.pending_data = []\n",
    "        self.description = ''\n",
    "        self.description_history = []\n",
    "        self.initiated = False \n",
    "    \n",
    "    def get_prompt_command(self):\n",
    "        if self.initiated==False:\n",
    "            return 'Write a paragraph describing the persona for the people who wrote the following reviews: \\n'\n",
    "        else:\n",
    "            return f'Write a paragraph updating the persona below based on the following additional reviews: \\n current persona: {self.description} \\nReviews: \\n'\n",
    "    \n",
    "    def update_description(self, description:str):\n",
    "        # print(f'Updating description: {description}')\n",
    "        self.description_history.append(description)\n",
    "        self.description = description\n",
    "        return \n",
    "        \n",
    "    \n",
    "    def process_persona(self):\n",
    "        iter=1\n",
    "        self.pending_data = []\n",
    "        while len(self.unprocessed_data)>0:\n",
    "            prompt = self.get_prompt_command()\n",
    "            while len(tokenizer.encode(prompt))< 2000:\n",
    "                if len(self.unprocessed_data)==0:\n",
    "                    break\n",
    "                review = self.unprocessed_data.pop(0)\n",
    "                prompt += f'- {review}\\n'\n",
    "                self.pending_data.append(review)\n",
    "            \n",
    "            if len(self.pending_data)==0:\n",
    "                raise ValueError('Cannot process any more data because max token limit was reached')\n",
    "            \n",
    "            print(f'Persona {self.cluster_id} - Iteration {iter} - batch size: {len(self.pending_data)} / {self.total_reviews}')\n",
    "            \n",
    "            res = openai.Completion.create(\n",
    "                prompt=prompt, \n",
    "                engine=os.getenv('OPENAI_COMPLETION_MODEL'), \n",
    "                max_tokens=2000, \n",
    "                temperature=0.7, \n",
    "                top_p=1, \n",
    "                frequency_penalty=0, \n",
    "                presence_penalty=0.6, \n",
    "                # stop=['\\n'],\n",
    "            )\n",
    "            ans = res.choices[0].text \n",
    "            self.initiated = True\n",
    "            self.update_description(ans)\n",
    "            self.processed_data += self.pending_data\n",
    "            self.pending_data = []\n",
    "        return \n",
    "                \n",
    "    def create_marketing_msg(self):\n",
    "        prompt = f'Write a marketing message for the persona below: \\n {self.description}'\n",
    "        res = openai.Completion.create(\n",
    "            prompt=prompt,\n",
    "            engine=os.getenv('OPENAI_COMPLETION_MODEL'), \n",
    "            max_tokens = 500,\n",
    "        )\n",
    "        self.marketing_msg = res.choices[0].text\n",
    "        return self.marketing_msg\n",
    "    \n",
    "    def __str__(self):\n",
    "        s = f'Persona {self.cluster_id} \\n {self.description} \\n {self.marketing_msg}'\n",
    "        ans = []\n",
    "        for txt in s.split('\\n'):\n",
    "            while len(txt)> 100:\n",
    "                a = txt[:100]\n",
    "                txt = txt[100:]\n",
    "                ans.append(a)\n",
    "            ans.append(txt)\n",
    "        return '\\n'.join(ans)\n",
    "        \n",
    "    \n",
    "def create_persona(df: pd.DataFrame)->list[Persona]:\n",
    "    personas = []\n",
    "    for cluster_id in df.cluster_id.unique():\n",
    "        data = df[df.cluster_id==cluster_id]['clean_text'].to_list()\n",
    "        persona = Persona(cluster_id, data)\n",
    "        persona.process_persona()\n",
    "        persona.create_marketing_msg()\n",
    "        personas.append(persona)\n",
    "    return personas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= read_df('../data/product-fire-hd-10.csv' )\n",
    "df['clean_text'] = clean_up_text(df['reviews.title'], df['reviews.text'])\n",
    "df['n_tokens'] = count_tokens(df['clean_text'])\n",
    "# print(df['n_tokens'].describe())\n",
    "emb_series, emb_matrix = get_embedding(df['clean_text'])\n",
    "reduced_matrix = perform_pca(emb_matrix)\n",
    "df['cluster_id'] = perform_clustering(reduced_matrix)\n",
    "personas = create_persona(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in personas:\n",
    "    print(p)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
